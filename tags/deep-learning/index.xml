<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deep Learning on 御風翱翔 知識漫遊</title>
    <link>https://imprld01.github.io/blogg/tags/deep-learning/</link>
    <description>Recent content in Deep Learning on 御風翱翔 知識漫遊</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 08 Jul 2022 21:00:00 +0000</lastBuildDate><atom:link href="https://imprld01.github.io/blogg/tags/deep-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>使用 Android NDK 編譯 Arm NN</title>
      <link>https://imprld01.github.io/blogg/2022/07/08/note_of_compilation_of_arm_nn_by_android_ndk/</link>
      <pubDate>Fri, 08 Jul 2022 21:00:00 +0000</pubDate>
      
      <guid>https://imprld01.github.io/blogg/2022/07/08/note_of_compilation_of_arm_nn_by_android_ndk/</guid>
      <description>版本對齊 Android API Version：29 System：aarch64、armv7a Arm NN：branches/armnn_22_05 Android NDK：andr</description>
    </item>
    
    <item>
      <title>Arm NN 的交叉編譯筆記</title>
      <link>https://imprld01.github.io/blogg/2022/06/25/note_of_cross_compilation_on_arm_nn/</link>
      <pubDate>Sat, 25 Jun 2022 21:00:00 +0000</pubDate>
      
      <guid>https://imprld01.github.io/blogg/2022/06/25/note_of_cross_compilation_on_arm_nn/</guid>
      <description>框架概念 (Concept of Arm NN ML Software) 支援 Post-Quantization 與 QAT Model armnn Quantizer 格式轉換 (convert to Arm NN format) armnn Converter armnn Serializer 交叉編譯 (Cross Compilation) 在ubuntu常會使用 gcc 或 g++ 指令編譯 c 程式，但是對於嵌入式系統或是</description>
    </item>
    
    <item>
      <title>Pytorch筆記: Quantization Aware Training (QAT)</title>
      <link>https://imprld01.github.io/blogg/2021/12/10/note_of_quantization_aware_training_in_pytorch/</link>
      <pubDate>Fri, 10 Dec 2021 21:00:00 +0000</pubDate>
      
      <guid>https://imprld01.github.io/blogg/2021/12/10/note_of_quantization_aware_training_in_pytorch/</guid>
      <description>Natively Supported Backends Content From Pytorch Official Website: When preparing a quantized model, it is necessary to ensure that qconfig and the engine used for quantized computations match the backend on which the model will be executed. The qconfig controls the type of observers used during the quantization passes. The qengine controls whether fbgemm or qnnpack specific packing function is used when packing weights for linear and convolution functions and</description>
    </item>
    
  </channel>
</rss>
